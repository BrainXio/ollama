{
  "quantization_weights": {
    "Q8_0": 1.0,
    "Q6_K": 0.75,
    "Q5_0": 0.625,
    "Q5_1": 0.65,
    "Q5_K_S": 0.65,
    "Q5_K_M": 0.68,
    "Q4_0": 0.5,
    "Q4_1": 0.55,
    "Q4_K_S": 0.55,
    "Q4_K_M": 0.57,
    "Q3_K_S": 0.38,
    "Q3_K_M": 0.4,
    "Q3_K_L": 0.45,
    "Q2_K": 0.3,
    "FP16": 2.0,
    "Q6_0": 0.75,
    "Q3_0": 0.375,
    "Q2_0": 0.25
  },
  "model_specs": {
    "qwen2.5-coder:0.5b": {
      "layers": 24,
      "hidden_size": 1024,
      "num_attention_heads": 14,
      "num_key_value_heads": 2,
      "max_position_embeddings": 32768
    },
    "qwen2.5-coder:1.5b": {
      "layers": 28,
      "hidden_size": 1536,
      "num_attention_heads": 12,
      "num_key_value_heads": 2,
      "max_position_embeddings": 32768
    },
    "qwen2.5-coder:3b": {
      "layers": 36,
      "hidden_size": 2048,
      "num_attention_heads": 16,
      "num_key_value_heads": 2,
      "max_position_embeddings": 32768
    },
    "qwen2.5-coder:7b": {
      "layers": 28,
      "hidden_size": 3584,
      "num_attention_heads": 28,
      "num_key_value_heads": 4,
      "max_position_embeddings": 131072
    },
    "qwen2.5-coder:14b": {
      "layers": 40,
      "hidden_size": 5120,
      "num_attention_heads": 40,
      "num_key_value_heads": 8,
      "max_position_embeddings": 131072
    },
    "qwen2.5-coder:32b": {
      "layers": 64,
      "hidden_size": 5120,
      "num_attention_heads": 40,
      "num_key_value_heads": 8,
      "max_position_embeddings": 131072
    },
    "deepseek-coder-v2:16b": {
      "layers": 27,
      "hidden_size": 2048,
      "num_attention_heads": 16,
      "num_key_value_heads": 2,
      "max_position_embeddings": 32768
    },
    "llama3.1:8b": {
      "layers": 32,
      "hidden_size": 4096,
      "num_attention_heads": 32,
      "num_key_value_heads": 8,
      "max_position_embeddings": 128000
    },
    "nomic-embed-text": {
      "layers": 12,
      "hidden_size": 768,
      "num_attention_heads": 12,
      "num_key_value_heads": 12,
      "max_position_embeddings": 8192
    },
    "codellama:13b": {
      "layers": 40,
      "hidden_size": 5120,
      "num_attention_heads": 40,
      "num_key_value_heads": 40,
      "max_position_embeddings": 16384
    },
    "mistral:7b": {
      "layers": 32,
      "hidden_size": 4096,
      "num_attention_heads": 32,
      "num_key_value_heads": 8,
      "max_position_embeddings": 32768
    },
    "codegemma:2b": {
      "layers": 18,
      "hidden_size": 2048,
      "num_attention_heads": 8,
      "num_key_value_heads": 1,
      "max_position_embeddings": 8192
    },
    "codegemma:7b": {
      "layers": 28,
      "hidden_size": 3072,
      "num_attention_heads": 16,
      "num_key_value_heads": 1,
      "max_position_embeddings": 8192
    },
    "deepseek-coder-v2:236b": {
      "layers": 60,
      "hidden_size": 6144,
      "num_attention_heads": 48,
      "num_key_value_heads": 16,
      "max_position_embeddings": 128000
    },
    "deepseek-coder:6.7b": {
      "layers": 30,
      "hidden_size": 4096,
      "num_attention_heads": 32,
      "num_key_value_heads": 32,
      "max_position_embeddings": 16384
    },
    "deepseek-coder:33b": {
      "layers": 40,
      "hidden_size": 5120,
      "num_attention_heads": 40,
      "num_key_value_heads": 40,
      "max_position_embeddings": 16384
    },
    "llama3.2:1b": {
      "layers": 16,
      "hidden_size": 2048,
      "num_attention_heads": 32,
      "num_key_value_heads": 8,
      "max_position_embeddings": 128000
    },
    "llama3.2:3b": {
      "layers": 22,
      "hidden_size": 2048,
      "num_attention_heads": 32,
      "num_key_value_heads": 4,
      "max_position_embeddings": 128000
    },
    "mixtral:8x7b": {
      "layers": 32,
      "hidden_size": 4096,
      "num_attention_heads": 32,
      "num_key_value_heads": 8,
      "max_position_embeddings": 32768
    },
    "mixtral:8x22b": {
      "layers": 56,
      "hidden_size": 6144,
      "num_attention_heads": 48,
      "num_key_value_heads": 8,
      "max_position_embeddings": 65536
    },
    "codestral:22b": {
      "layers": 40,
      "hidden_size": 5120,
      "num_attention_heads": 40,
      "num_key_value_heads": 8,
      "max_position_embeddings": 32768
    },
    "starcoder2:3b": {
      "layers": 28,
      "hidden_size": 3072,
      "num_attention_heads": 24,
      "num_key_value_heads": 1,
      "max_position_embeddings": 16384
    },
    "starcoder2:7b": {
      "layers": 32,
      "hidden_size": 4096,
      "num_attention_heads": 32,
      "num_key_value_heads": 1,
      "max_position_embeddings": 16384
    },
    "starcoder2:15b": {
      "layers": 40,
      "hidden_size": 6144,
      "num_attention_heads": 48,
      "num_key_value_heads": 1,
      "max_position_embeddings": 16384
    },
    "wizardcoder:15b": {
      "layers": 40,
      "hidden_size": 6144,
      "num_attention_heads": 48,
      "num_key_value_heads": 1,
      "max_position_embeddings": 8192
    },
    "wizardcoder:33b": {
      "layers": 43,
      "hidden_size": 7168,
      "num_attention_heads": 56,
      "num_key_value_heads": 8,
      "max_position_embeddings": 16384
    },
    "deepseek-v3:671b": {
      "layers": 61,
      "hidden_size": 7168,
      "num_attention_heads": 56,
      "num_key_value_heads": 8,
      "max_position_embeddings": 128000
    },
    "llama3.1:70b": {
      "layers": 80,
      "hidden_size": 8192,
      "num_attention_heads": 64,
      "num_key_value_heads": 8,
      "max_position_embeddings": 131072
    },
    "gemma2:2b": {
      "layers": 26,
      "hidden_size": 2304,
      "num_attention_heads": 8,
      "num_key_value_heads": 4,
      "max_position_embeddings": 8192
    },
    "gemma2:9b": {
      "layers": 42,
      "hidden_size": 3584,
      "num_attention_heads": 16,
      "num_key_value_heads": 8,
      "max_position_embeddings": 8192
    },
    "gemma2:27b": {
      "layers": 46,
      "hidden_size": 4608,
      "num_attention_heads": 32,
      "num_key_value_heads": 16,
      "max_position_embeddings": 8192
    },
    "phi3.5:3.8b": {
      "layers": 32,
      "hidden_size": 3072,
      "num_attention_heads": 32,
      "num_key_value_heads": 32,
      "max_position_embeddings": 131072
    },
    "codellama:7b": {
      "layers": 32,
      "hidden_size": 4096,
      "num_attention_heads": 32,
      "num_key_value_heads": 32,
      "max_position_embeddings": 16384
    },
    "codellama:34b": {
      "layers": 48,
      "hidden_size": 8192,
      "num_attention_heads": 64,
      "num_key_value_heads": 8,
      "max_position_embeddings": 16384
    },
    "codellama:70b": {
      "layers": 80,
      "hidden_size": 8192,
      "num_attention_heads": 64,
      "num_key_value_heads": 8,
      "max_position_embeddings": 16384
    },
    "phi4:4b": {
      "layers": 32,
      "hidden_size": 3072,
      "num_attention_heads": 24,
      "num_key_value_heads": 8,
      "max_position_embeddings": 131072
    },
    "deepseek-r1:671b": {
      "layers": 61,
      "hidden_size": 7168,
      "num_attention_heads": 56,
      "num_key_value_heads": 8,
      "max_position_embeddings": 128000
    },
    "codestral:25.01": {
      "layers": 40,
      "hidden_size": 5120,
      "num_attention_heads": 40,
      "num_key_value_heads": 8,
      "max_position_embeddings": 32768
    },
    "llama4:scout": {
      "layers": 80,
      "hidden_size": 8192,
      "num_attention_heads": 64,
      "num_key_value_heads": 8,
      "max_position_embeddings": 10000000
    },
    "llama4:maverick": {
      "layers": 120,
      "hidden_size": 12288,
      "num_attention_heads": 96,
      "num_key_value_heads": 8,
      "max_position_embeddings": 10000000
    },
    "deepseek-coder-v2-lite:16b": {
      "layers": 27,
      "hidden_size": 2048,
      "num_attention_heads": 16,
      "num_key_value_heads": 16,
      "max_position_embeddings": 163840
    },
    "codegemma:2b-v1.1": {
      "layers": 18,
      "hidden_size": 2048,
      "num_attention_heads": 8,
      "num_key_value_heads": 1,
      "max_position_embeddings": 8192
    },
    "mistral:7b-v0.3": {
      "layers": 32,
      "hidden_size": 4096,
      "num_attention_heads": 32,
      "num_key_value_heads": 8,
      "max_position_embeddings": 32768
    },
    "mistral:7b-v0.2": {
      "layers": 32,
      "hidden_size": 4096,
      "num_attention_heads": 32,
      "num_key_value_heads": 8,
      "max_position_embeddings": 32768
    },
    "llama3.1:8b-code": {
      "layers": 32,
      "hidden_size": 4096,
      "num_attention_heads": 32,
      "num_key_value_heads": 8,
      "max_position_embeddings": 128000
    },
    "llama3.1:70b-text": {
      "layers": 80,
      "hidden_size": 8192,
      "num_attention_heads": 64,
      "num_key_value_heads": 8,
      "max_position_embeddings": 131072
    },
    "codellama:13b-code": {
      "layers": 40,
      "hidden_size": 5120,
      "num_attention_heads": 40,
      "num_key_value_heads": 40,
      "max_position_embeddings": 16384
    }
  }
}