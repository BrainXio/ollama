---
name: ollama

# Base configuration for Ollama initialization, pulling specified models
x-init-ollama: &init-ollama
  command:
    - -c
    - |
      sleep 3;
      # ollama pull ${OLLAMA_BASE_MODEL:-smollm2};
      ollama pull ${OLLAMA_READ_LM:-read-lm:latest};
      # ollama pull $${OLLAMA_EMBEDDING_MODEL:-smollm2};
      # ollama pull $${OLLAMA_THINKING_MODEL:-smollm2};
      # ollama pull $${OLLAMA_TOOLS_MODEL:-smollm2};
      # ollama pull $${OLLAMA_VISION_MODEL:-smollm2};
  container_name: ollama-init
  entrypoint: /bin/sh
  environment:
    - OLLAMA_HOST=ollama:11434
  env_file:
    - .env
  image: ollama/ollama:${OLLAMA_VERSION:-latest}
  volumes:
    - ${OLLAMA_VOLUME:-ollama-data}:/root/.ollama

# Base configuration for Ollama service, defining common settings
x-ollama: &service-ollama
  container_name: ollama
  environment:
    - OLLAMA_FLASH_ATTENTION=${OLLAMA_FLASH_ATTENTION:-1}
    - OLLAMA_KV_CACHE_TYPE=${OLLAMA_KV_CACHE_TYPE:-q8_0}
    - OLLAMA_MAX_LOADED_MODELS=${OLLAMA_MAX_LOADED_MODELS:-4}
    - OLLAMA_KEEP_ALIVE=${OLLAMA_KEEP_ALIVE:-30m}
  image: ollama/ollama:${OLLAMA_VERSION:-latest}
  restart: unless-stopped
  volumes:
    - ${OLLAMA_VOLUME:-ollama-data}:/root/.ollama

# Secret for Tailscale authentication key
secrets:
  tsauthkey:
    file: ${TSAUTHKEY_PATH:-tsauthkey}

# ==============================================================================
# Base Ollama Services (CPU, GPU-NVIDIA, GPU-AMD)
# ==============================================================================
services:
  # Ollama service for CPU, exposing port 11434 and using ollama-network
  ollama-cpu:
    <<: *service-ollama
    profiles:
      - cpu
    ports:
      - ${OLLAMA_PORT:-127.0.0.1:11434}:11434
    networks:
      - ollama-network

  # Ollama service for NVIDIA GPU, with GPU reservation and network configuration
  ollama-gpu:
    <<: *service-ollama
    deploy:
      resources:
        reservations:
          devices:
            - capabilities:
                - gpu
              count: 1
              driver: nvidia
    profiles:
      - gpu-nvidia
    ports:
      - ${OLLAMA_PORT:-127.0.0.1:11434}:11434
    networks:
      - ollama-network

  # Ollama service for AMD GPU, using ROCm image and device mappings
  ollama-gpu-amd:
    <<: *service-ollama
    devices:
      - /dev/kfd
      - /dev/dri
    image: ollama/ollama:rocm
    profiles:
      - gpu-amd
    ports:
      - ${OLLAMA_PORT:-127.0.0.1:11434}:11434
    networks:
      - ollama-network

  # ==============================================================================
  # Ollama Initialization Services (Pull Models for CPU, GPU-NVIDIA, GPU-AMD)
  # ==============================================================================
  ollama-init-pull-cpu:
    <<: *init-ollama
    depends_on:
      - ollama-cpu
    profiles:
      - cpu

  ollama-init-pull-gpu:
    <<: *init-ollama
    depends_on:
      - ollama-gpu
    image: ollama/ollama:${OLLAMA_VERSION:-latest}
    profiles:
      - gpu-nvidia

  ollama-init-pull-gpu-amd:
    <<: *init-ollama
    depends_on:
      - ollama-gpu-amd
    image: ollama/ollama:rocm
    profiles:
      - gpu-amd

  # ==============================================================================
  # Tailscale-Enabled Ollama Services
  # ==============================================================================
  ollama-cpu-tailscale:
    <<: *service-ollama
    depends_on:
      - tailscale
    network_mode: service:tailscale
    profiles:
      - tailscale-cpu
      - tailscale

  ollama-gpu-tailscale:
    <<: *service-ollama
    depends_on:
      - tailscale
    network_mode: service:tailscale
    deploy:
      resources:
        reservations:
          devices:
            - capabilities:
                - gpu
              count: 1
              driver: nvidia
    profiles:
      - tailscale-gpu-nvidia
      - tailscale
    image: ollama/ollama:${OLLAMA_VERSION:-latest}

  ollama-gpu-amd-tailscale:
    <<: *service-ollama
    depends_on:
      - tailscale
    network_mode: service:tailscale
    devices:
      - /dev/kfd
      - /dev/dri
    image: ollama/ollama:rocm
    profiles:
      - tailscale-gpu-amd
      - tailscale

  tailscale:
    cap_add:
      - NET_ADMIN
      - SYS_MODULE
    container_name: ollama-ts
    devices:
      - /dev/net/tun:/dev/net/tun
    environment:
      - TS_EXTRA_ARGS=--auth-key file:/run/secrets/tsauthkey
      - TS_STATE_DIR=/var/lib/tailscale
      - TS_USERSPACE=false
    hostname: ${TAILSCALE_HOSTNAME:-ollama}
    image: tailscale/tailscale:${TAILSCALE_VERSION:-stable}
    restart: unless-stopped
    secrets:
      - tsauthkey
    volumes:
      - tailscale-state:/var/lib/tailscale
    profiles:
      - tailscale
      - tailscale-cpu
      - tailscale-gpu-nvidia
      - tailscale-gpu-amd
    labels:
      - traefik.enable=${OLLAMA_ENABLE_TRAEFIK:-false}
      - traefik.docker.network=ollama-network
      - traefik.http.middlewares.ip-whitelist.ipallowlist.sourcerange=${IP_WHITELIST:-0.0.0.0/0}
      - traefik.http.middlewares.ollama-network-redirect.redirectscheme.scheme=https
      - traefik.http.routers.ollama.entrypoints=web
      - traefik.http.routers.ollama.middlewares=ollama-network-redirect
      - traefik.http.routers.ollama.rule=Host(`ollama.${DOMAIN:-}`)
      - traefik.http.routers.ollama-secure.entrypoints=websecure
      - traefik.http.routers.ollama-secure.rule=Host(`ollama.${DOMAIN:-}`)
      - traefik.http.routers.ollama-secure.service=ollama
      - traefik.http.routers.ollama-secure.tls=true
      - traefik.http.services.ollama.loadbalancer.server.port=11434
    networks:
      - ollama-network
    ports:
      - ${OLLAMA_PORT:-127.0.0.1:11434}:11434

# ==============================================================================
# Volumes and Networks
# ==============================================================================
volumes:
  # Persistent volume for Ollama data, defaults to ollama-data if OLLAMA_VOLUME not set
  ollama-data:
  # Persistent volume for Tailscale state
  tailscale-state:

networks:
  # Network for Ollama and Traefik integration, configurable via OLLAMA_NETWORK_NAME
  ollama-network:
    name: ${OLLAMA_NETWORK_NAME:-ollama-net}
    external: ${OLLAMA_NETWORK_EXTERNAL:-false}
