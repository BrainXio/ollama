---
name: ollama

# Base configuration for Ollama initialization, pulling specified models
x-init-ollama: &init-ollama
  command:
    - -c
    - |
      sleep 3;
      echo "ollama pull $${OLLAMA_BASE_MODEL:-smollm2}";
      ollama pull $${OLLAMA_BASE_MODEL:-smollm2};
      echo "ollama pull $${OLLAMA_EMBED_MODEL:-nomic-embed-text}";
      ollama pull $${OLLAMA_EMBED_MODEL:-nomic-embed-text};
      echo "ollama pull $${OLLAMA_GUARD_MODEL:-granite3-guardian:2b}";
      ollama pull $${OLLAMA_GUARD_MODEL:-granite3-guardian:2b};
      echo "ollama pull $${OLLAMA_HTML_MODEL:-reader-lm:1.5b}";
      ollama pull $${OLLAMA_HTML_MODEL:-reader-lm:1.5b};
      echo "ollama pull $${OLLAMA_THINKING_MODEL:-deepseek-r1:1.5b}";
      ollama pull $${OLLAMA_THINKING_MODEL:-deepseek-r1:1.5b};
      echo "ollama pull $${OLLAMA_TOOLS_MODEL:-granite3.1-moe:1b}";
      ollama pull $${OLLAMA_TOOLS_MODEL:-granite3.1-moe:1b};
      echo "ollama pull $${OLLAMA_VISION_MODEL:-granite3.2-vision:2b}";
      ollama pull $${OLLAMA_VISION_MODEL:-granite3.2-vision:2b};
  container_name: ollama-init
  entrypoint: /bin/sh
  environment:
    - OLLAMA_HOST=${TAILSCALE_HOSTNAME:-ollama}:11434
  env_file:
    - .env
  image: ollama/ollama:${OLLAMA_VERSION:-latest}
  volumes:
    - ${OLLAMA_VOLUME:-ollama-data}:/root/.ollama
  networks:
    - ollama-network

# Base configuration for Ollama service, defining common settings
x-ollama: &service-ollama
  container_name: ollama
  environment:
    - OLLAMA_FLASH_ATTENTION=${OLLAMA_FLASH_ATTENTION:-1}
    - OLLAMA_KV_CACHE_TYPE=${OLLAMA_KV_CACHE_TYPE:-q8_0}
    - OLLAMA_KEEP_ALIVE=${OLLAMA_KEEP_ALIVE:-30m}
    - OLLAMA_MAX_LOADED_MODELS=${OLLAMA_MAX_LOADED_MODELS:-4}
    - OLLAMA_NUM_CTX=${OLLAMA_NUM_CTX:-8192}
  image: ollama/ollama:${OLLAMA_VERSION:-latest}
  restart: unless-stopped
  volumes:
    - ${OLLAMA_VOLUME:-ollama-data}:/root/.ollama

# Base configuration for Tailscale service, aligned with n8n
x-tailscale: &service-tailscale
  cap_add:
    - NET_ADMIN
    - SYS_MODULE
  devices:
    - /dev/net/tun:/dev/net/tun
  environment:
    - TS_EXTRA_ARGS=--auth-key file:/run/secrets/tsauthkey --accept-dns
    - TS_STATE_DIR=/var/lib/tailscale
    - TS_USERSPACE=false
  image: tailscale/tailscale:${TAILSCALE_VERSION:-stable}
  restart: unless-stopped
  secrets:
    - tsauthkey
  volumes:
    - tailscale-state:/var/lib/tailscale

# Secret for Tailscale authentication key
secrets:
  tsauthkey:
    file: ${TSAUTHKEY_PATH:-./secrets/tsauthkey}

# ==============================================================================
# Base Ollama Services (CPU, GPU-NVIDIA, GPU-AMD)
# ==============================================================================
services:
  # Ollama service for CPU, exposing port 11434 and using ollama-network
  ollama-cpu:
    <<: *service-ollama
    profiles:
      - cpu
    ports:
      - ${OLLAMA_PORT:-127.0.0.1:11434}:11434
    networks:
      - ollama-network

  # Ollama service for NVIDIA GPU, with GPU reservation and network configuration
  ollama-gpu:
    <<: *service-ollama
    deploy:
      resources:
        reservations:
          devices:
            - capabilities:
                - gpu
              count: 1
              driver: nvidia
    profiles:
      - nvidia-gpu
    ports:
      - ${OLLAMA_PORT:-127.0.0.1:11434}:11434
    networks:
      - ollama-network

  # Ollama service for AMD GPU, using ROCm image and device mappings
  ollama-amd-gpu:
    <<: *service-ollama
    devices:
      - /dev/kfd
      - /dev/dri
    image: ollama/ollama:rocm
    profiles:
      - amd-gpu
    ports:
      - ${OLLAMA_PORT:-127.0.0.1:11434}:11434
    networks:
      - ollama-network

  # ==============================================================================
  # Ollama Initialization Services (Pull Models for CPU, GPU-NVIDIA, GPU-AMD)
  # ==============================================================================
  ollama-init-pull-cpu:
    <<: *init-ollama
    depends_on:
      - ollama-cpu
    profiles:
      - cpu

  ollama-init-pull-nvidia-gpu:
    <<: *init-ollama
    depends_on:
      - ollama-gpu
    image: ollama/ollama:${OLLAMA_VERSION:-latest}
    profiles:
      - nvidia-gpu

  ollama-init-pull-amd-gpu:
    <<: *init-ollama
    depends_on:
      - ollama-amd-gpu
    image: ollama/ollama:rocm
    profiles:
      - amd-gpu

  # ==============================================================================
  # Tailscale-Enabled Ollama Services
  # ==============================================================================
  ollama-init-pull-cpu-tailscale:
    <<: *init-ollama
    depends_on:
      - ollama-cpu-tailscale
    profiles:
      - tailscale-cpu

  ollama-init-pull-nvidia-gpu-tailscale:
    <<: *init-ollama
    depends_on:
      - ollama-nvidia-gpu-tailscale
    image: ollama/ollama:${OLLAMA_VERSION:-latest}
    profiles:
      - tailscale-nvidia-gpu

  ollama-init-pull-amd-gpu-tailscale:
    <<: *init-ollama
    depends_on:
      - ollama-amd-gpu-tailscale
    image: ollama/ollama:rocm
    profiles:
      - tailscale-amd-gpu

  ollama-cpu-tailscale:
    <<: *service-ollama
    depends_on:
      - tailscale
    network_mode: service:tailscale
    profiles:
      - tailscale-cpu

  ollama-nvidia-gpu-tailscale:
    <<: *service-ollama
    depends_on:
      - tailscale
    network_mode: service:tailscale
    deploy:
      resources:
        reservations:
          devices:
            - capabilities:
                - gpu
              count: 1
              driver: nvidia
    profiles:
      - tailscale-nvidia-gpu
    image: ollama/ollama:${OLLAMA_VERSION:-latest}

  ollama-amd-gpu-tailscale:
    <<: *service-ollama
    depends_on:
      - tailscale
    network_mode: service:tailscale
    devices:
      - /dev/kfd
      - /dev/dri
    image: ollama/ollama:rocm
    profiles:
      - tailscale-amd-gpu

  tailscale:
    <<: *service-tailscale
    container_name: ollama-ts
    hostname: ${TAILSCALE_HOSTNAME:-ollama}
    networks:
      - ollama-network
    ports:
      - ${OLLAMA_PORT:-127.0.0.1:11434}:11434
    profiles:
      - tailscale
      - tailscale-cpu
      - tailscale-nvidia-gpu
      - tailscale-amd-gpu

# ==============================================================================
# Volumes and Networks
# ==============================================================================
volumes:
  # Persistent volume for Ollama data, defaults to ollama-data if OLLAMA_VOLUME not set
  ollama-data:
  # Persistent volume for Tailscale state
  tailscale-state:

networks:
  # Network for Ollama and Traefik integration, configurable via OLLAMA_NETWORK_NAME
  ollama-network:
    name: ${OLLAMA_NETWORK_NAME:-ollama-net}
    external: ${OLLAMA_NETWORK_EXTERNAL:-false}
